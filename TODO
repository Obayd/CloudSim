New Bug: high memory bound is not being read correctly from input (check output)

*** Need more sanity checks in code. Just to play safe.

****
- Add monitors
- Account costs in cloud machine (when finish job)
- Notify scheduler when job is finished
- Create and activate machines in the schedule
- Add shutdown machine support
- Add support to partial quantums (when the number of remaining instructions is samller than the number of instructions per quantum)

***

- Web request mode

- Global scenario object?

- Worker node stuff:
	- Change the working unit from time-to-execute-task to number-of-instructions-per-job.
	- Add memory thingy to nodes.
	- Round robin CPU scheduler for the nodes.
	- Swap in-out of jobs on the nodes. This has a cost of instructions per MB attached to it.
	- Ultimately, a worker node has (instructions/sec, memory, swap-cost, startup-time, scheduler notification time, cost per hour). All configurable.

- Add cost factor to the workers.


- Doubts to ask:
		- Single task versus Web request? :|
		- Maximum number of worker nodes? Is it:
					a) We can launch as many nodes as we have processes?
		- Perfect scheduling? What does the last line in 2.2 mean?
